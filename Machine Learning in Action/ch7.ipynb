{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d225d859-810f-4806-851b-cfa8e7307851",
   "metadata": {},
   "source": [
    "# 第 7 章 利用AdaBoost元算法提高分类性能\n",
    "\n",
    "**本章内容**\n",
    "- 组合相似的分类器来提高分类性能\n",
    "- 应用AdaBoost算法\n",
    "- 处理非均衡分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642d5bc-3a2b-4fb1-84cc-1854140f7e9a",
   "metadata": {},
   "source": [
    "## 7.1 基于数据集多重抽样的分类器\n",
    "\n",
    "我们可以通过**集成方法**（*ensemble method*）将不同的分类器组合起来，从而实现“三个臭皮匠顶个诸葛亮”的效果。\n",
    "\n",
    "集成方法在使用时可以有多种形式：\n",
    "- 不同算法的集成\n",
    "- 同一算法在不同设置下的集成\n",
    "- 数据集不同部分分配给不同分类器之后的集成\n",
    "\n",
    "接下来，我们将介绍基于同一种分类器多个不同实例的两种计算方法。在这些方法当中，数据集也会不断变化，而后应用于不通的实例分类器上。最后，我们会讨论如何利用机器学习问题的通用框架来应用AdaBoost算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21940267-4743-463c-a9a0-ee0870ca44e0",
   "metadata": {},
   "source": [
    "||AdaBoost|\n",
    "|---|---|\n",
    "|优点|泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整。|\n",
    "|缺点|对离群点敏感。|\n",
    "|适用数据类型|数值型、标称型。|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f6e97-4ac5-4776-b390-71971e952d0b",
   "metadata": {},
   "source": [
    "### 7.1.1 bagging：基于数据随机重抽样的分类器构建方法\n",
    "\n",
    "bagging方法，是从原始数据集选择S次后得到S个新数据集的一种技术。新数据集和原数据集的大小相等。每个数据集都是通过在原始数据集中随机选择一个样本来进行替换而得到的（有放回抽样）。\n",
    "\n",
    "在S个数据集建好之后，将某个学习算法分别作用于每个数据集就得到了S个分类器。\n",
    "\n",
    "当我们要对新数据进行分类时，就可以应用这S个分类器进行分类。与此同时，选择分类器投票结果中最多的类别作为最后的分类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268aa31-3cba-4113-8269-a29a8a9d0b6f",
   "metadata": {},
   "source": [
    "### 7.1.2 boosting\n",
    "\n",
    "boosting是一种类似bagging的集成方法，不同之处在于boosting的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。\n",
    "\n",
    "此外关于权重的分配，bagging方法中各个分类器的权重是相等的，而boosting方法中各个分类器的权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。\n",
    "\n",
    "boosting方法拥有多个版本，本章将只关注其中一个最流行的版本——AdaBoost。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ae298-12a0-4033-97e3-50babb0532d2",
   "metadata": {},
   "source": [
    "|||AdaBoost的一般流程|\n",
    "|---|---|---|\n",
    "|(1)|收集数据：|可以使用任意方法。|\n",
    "|(2)|准备数据：|依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器（如第2章到第6章中的任意分类器）。作为弱分类器，简单分类器的效果更好。|\n",
    "|(3)|分析数据：|可以使用任意方法。|\n",
    "|(4)|训练算法：|AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。|\n",
    "|(5)|测试算法：|计算分类的错误率。|\n",
    "|(6)|使用算法：|同SVM一样，AdaBoost预测两个类别中的一个。如果想把它应用到多个类别的场合，那么就要像多类SVM中的做法一样对AdaBoost进行修改。|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c498c2-acee-4334-967b-07eb7a752147",
   "metadata": {},
   "source": [
    "下面我们将要讨论AdaBoost背后的一些理论，兵揭示其效果不错的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a921d3-d5e6-4e4e-a300-440919862f5a",
   "metadata": {},
   "source": [
    "## 7.2 训练算法：基于错误提升分类器的性能\n",
    "\n",
    "AdaBoost的运行过程如下：\n",
    "\n",
    "(1) 赋予数量为$n$的训练数据中每个样本一个相等的权重$D_i$（通常为$\\frac{1}{n}$），这些权重构成向量$D$。\n",
    "\n",
    "(2) 在训练集上训练出一个弱分类器并计算该分类器的错误率$\\epsilon$。\n",
    "$$\n",
    "\\epsilon = \\frac{未正确分类的样本数量}{所有样本数量}\n",
    "$$\n",
    "\n",
    "(3) AdaBoost为每个分类器都分配了一个权重$\\alpha$，其计算公式如下：\n",
    "$$\n",
    "\\alpha = \\frac{1}{2}ln(\\frac{1-\\epsilon}{\\epsilon})\n",
    "$$\n",
    "\n",
    "(4) 根据$\\alpha$调整每个样本的权重，降低第一次分对样本的权重，提高第一次分错样本的权重。具体而言：\n",
    "\n",
    "对于被**正确**分类的样本，其权重更新为：\n",
    "\n",
    "$$\n",
    "D^{(t+1)}_i = \\frac{D^{(t)}_ie^{-\\alpha}}{Sum(D)}\n",
    "$$\n",
    "\n",
    "对于被**错误**分类的样本，其权重更新为：\n",
    "\n",
    "$$\n",
    "D^{(t+1)}_i = \\frac{D^{(t)}_ie^{\\alpha}}{Sum(D)}\n",
    "$$\n",
    "\n",
    "(5) 在相同数据集上利用调整好后的权重再次训练分类器。\n",
    "\n",
    "(6) 重复步骤（3）和（5），直至训练错误率变为0或弱分类器数量达到预设值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb9e97-b74c-40f4-b018-a79d57c5ae92",
   "metadata": {},
   "source": [
    "接下来，我们将建立完整的AdaBoost算法。在这之前，我们首先必须通过一些代码来建立弱分类器及保存数据集的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43de18-89e1-45f9-b953-5d9ad3bdf1f3",
   "metadata": {},
   "source": [
    "## 7.3 基于单层决策树构建弱分类器\n",
    "\n",
    "单层决策树（*decision stump*，也称决策桩）是一种简单的决策树，它仅基于单个特征来做决策。由于这棵树只有一次分裂过程，因此它实际上就是一个树桩。\n",
    "\n",
    "接下来我们在构建AdaBoost的代码时，将首先通过一个简单数据集来确保在算法实现上一切就绪。\n",
    "\n",
    "首先定义一个名为`loadSimpleData()`的函数用来生成简单数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9243c4e8-3293-4a9f-b628-b36329251d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c0bef86-1145-401a-afb5-e3315e1f9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpleData():\n",
    "    datMat = np.matrix([[1.0, 2.1],\n",
    "                        [2.0, 1.1],\n",
    "                        [1.3, 1.0],\n",
    "                        [1.0, 1.0],\n",
    "                        [2.0, 1.0]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat, classLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6ff08-170d-4353-bf81-fbe3b7c1b1b4",
   "metadata": {},
   "source": [
    "然后定义一个`plotting`方法来画出简单数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f81180c-94a1-459a-b55b-60f72e817901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(data, labels) -> None:\n",
    "    X1 = []\n",
    "    Y1 = []\n",
    "    X2 = []\n",
    "    Y2 = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if labels[i] == 1.0:\n",
    "            X1.append(data[i, 0])\n",
    "            Y1.append(data[i, 1])\n",
    "        elif labels[i] == -1.0:\n",
    "            X2.append(data[i, 0])\n",
    "            Y2.append(data[i, 1])\n",
    "        else:\n",
    "            pass\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(X1, Y1, marker='s', s=90)\n",
    "    ax.scatter(X2, Y2, marker='o', s=50, c='red')\n",
    "    plt.title('decision stump test data')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3b773-3acd-4167-9ca4-f675cbd2b0b7",
   "metadata": {},
   "source": [
    "接下来导入数据集和标签，并将其画出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bcaad6f-dbee-41c3-bdc7-8f97d7d0f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat, classLabels = loadSimpleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436aa478-cd30-4670-b17d-2c7587b78beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotting(datMat, classLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf554f5-b965-4c4a-9f6b-b4f5191028b8",
   "metadata": {},
   "source": [
    "从上图中可以看出，如果想要试着从某个坐标轴上选择一个值（即选择一条与坐标轴平行的直线）来将所有的圆形点和方形点分开，这显然是不可能的。也就是说，单层决策树无法解决这一类的问题。但是通过使用多棵单层决策树我们就可以构建出一个能正确分类的分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ca199-41a4-4275-818b-019e038186dd",
   "metadata": {},
   "source": [
    "这个程序的伪代码大致如下：\n",
    "\n",
    "（1）将最小错误率minError设为$\\infty$\n",
    "\n",
    "（2）对数据集中的每一个特征（第一层循环）：\n",
    "\n",
    "        对每个步长（第二层循环）：\n",
    "        \n",
    "            对每个不等号（第三层循环）：\n",
    "            \n",
    "                建立一棵单层决策树并利用加权数据集对它进行测试\n",
    "                \n",
    "                如果错误率低于minError，则将当前单层决策树设为最佳单层决策树\n",
    "                \n",
    "（3）返回最佳单层决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b606e-0424-4380-b014-caa4186119af",
   "metadata": {},
   "source": [
    "接下来我们将通过两个函数来构建单层决策树。其中第一个函数(`stumpClassify()`）将用于测试是否有某个值小于或者大于我们正在测试的阈值。第二个函数（`buildStump()`）则更加复杂一些，它会在一个加权数据集中循环，并找到具有最低错误率的单层决策树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a96cf2f-c3e0-4161-a4c5-656be5218c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0], 1))\n",
    "    if threshIneq == 'lt':    # less then\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ed124-c55f-4e42-8bad-51f21792c100",
   "metadata": {},
   "source": [
    "`stumpClassify()`函数通过阈值比较对数据进行分类。所有在阈值一边的数据会分到类别`-1`，而在另一边的数据会分到`+1`。这里的实现方式采用了数组过滤，首先将返回数组`retArray`的全部元素设为1，然后将所有不满足不等式要求的元素设为-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ae29876-157f-4468-96c9-775cfbb44d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr, classLabels, D):\n",
    "    dataMatrix = np.asmatrix(dataArr)\n",
    "    labelMat = np.asmatrix(classLabels).T\n",
    "    m, n = np.shape(dataArr)\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}\n",
    "    bestClasEst = np.asmatrix(np.zeros((m, 1)))\n",
    "    minError = np.inf\n",
    "\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:, i].min(); rangeMax = dataMatrix[:, i].max();\n",
    "        stepSize = (rangeMax - rangeMin) / numSteps\n",
    "        for j in range(-1, int(numSteps) + 1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                errArr = np.asmatrix(np.ones((m, 1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T * errArr\n",
    "                print(f\"split: dim {i}, thresh {threshVal:.2f}, thresh inequal: {inequal}, the weighted error is: {weightedError}\")\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClasEst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d51bec-131e-45c0-b7d0-378bd777e3b6",
   "metadata": {},
   "source": [
    "`buildStump()`会遍历`stumpClassify()`函数所有可能的输入值，并找到数据集上最佳的单层决策树。（这里的最佳是基于数据的权重向量`D`来定义的。）\n",
    "\n",
    "`buildStump()`会先确保输入数据符合矩阵格式，然后定义了一个`bestStump`的字典，用于存储给定权重向量$D$时所得到的最佳单层决策树的相关信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bf4ada7-f7fa-4b30-93bd-b8649af07f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.asmatrix(np.ones((5,1))/5)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7faf68c1-d3df-4377-982e-58886268adc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: dim 0, thresh 0.90, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 0.90, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: lt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: gt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: lt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: gt, the weighted error is: [[0.4]]\n"
     ]
    }
   ],
   "source": [
    "bestStump, minError, bestClasEst = buildStump(datMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60bfb8-e060-463f-ba48-c25004109dbb",
   "metadata": {},
   "source": [
    "上述单层决策树的生成函数是决策树的一个简化版本。它就是所谓的弱分类器，即弱分类算法。到现在为止，我们已经构建了单层决策树，并生成了程序，做好了过渡到完整AdaBoost算法的准备。\n",
    "\n",
    "在下一节中，我们将使用多个弱分类器来构建AdaBoost代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ea5ab-c768-49f5-b374-c493cbb1ca9a",
   "metadata": {},
   "source": [
    "## 7.4 完整AdaBoost算法的实现\n",
    "\n",
    "在上一节中，我们构建了一个基于加权输入值进行决策的分类器。现在我们拥有了实现一个完整AdaBoost算法所需要的所有信息。接下来我们将利用7.3节构建的单层决策树来实现7.2节中的算法。整个过程的伪代码如下：\n",
    "\n",
    "对每次迭代：\n",
    "    \n",
    "利用`buildStump()`函数找到最佳的单层决策树\n",
    "\n",
    "将最佳单层决策树加入到单层决策树组\n",
    "\n",
    "计算$\\alpha$\n",
    "\n",
    "计算新的权重向量$D$\n",
    "\n",
    "更新累计类别估计值\n",
    "\n",
    "如果错误率等于$0.0$，则退出循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1019871a-c1bd-47f0-ad5a-f83725fbbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.asmatrix(np.ones((m, 1)) / m)\n",
    "    aggClassEst = np.asmatrix(np.zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D)\n",
    "        print(f\"D: {D.T}\")\n",
    "        alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        print(f\"classEst: {classEst.T}\")\n",
    "        expon = np.multiply(-1 * alpha * np.matrix(classLabels).T, classEst)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D / D.sum()\n",
    "        aggClassEst += alpha * classEst\n",
    "        print(f\"aggClassEst: {aggClassEst.T}\")\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.asmatrix(classLabels).T, np.ones((m, 1)))\n",
    "        errorRate = aggErrors.sum() / m\n",
    "        print(f\"total error: {errorRate}\\n\")\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23490287-2d2f-4407-896a-3a53e340ecbb",
   "metadata": {},
   "source": [
    "我们定义了一个可以执行AdaBoost算法的函数：`adaBoostTrainDS()`，其中DS指的是单层决策树（decision stump），当然也可以用其他算法作为基分类器。\n",
    "\n",
    "它的输入参数包括数据集dataArr，类别标签classLabels和迭代次数numIt，其中numIt是整个AdaBoost算法中唯一需要用户指定的参数。\n",
    "\n",
    "它的输出则是一个单层决策树的数组。\n",
    "\n",
    "接下来让我们运行一下这段函数，假定迭代次数为9。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e13ae75-2d81-4013-b254-63c92e1426a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: dim 0, thresh 0.90, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 0.90, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: lt, the weighted error is: [[0.6]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: gt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.2]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.8]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: lt, the weighted error is: [[0.4]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: gt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: lt, the weighted error is: [[0.6]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: gt, the weighted error is: [[0.4]]\n",
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst: [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst: [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error: 0.2\n",
      "\n",
      "split: dim 0, thresh 0.90, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 0, thresh 0.90, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.625]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.375]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: lt, the weighted error is: [[0.625]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: gt, the weighted error is: [[0.375]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: lt, the weighted error is: [[0.625]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: gt, the weighted error is: [[0.375]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: lt, the weighted error is: [[0.75]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: gt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.125]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.875]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: lt, the weighted error is: [[0.25]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: gt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: lt, the weighted error is: [[0.75]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: gt, the weighted error is: [[0.25]]\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst: [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst: [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error: 0.2\n",
      "\n",
      "split: dim 0, thresh 0.90, thresh inequal: lt, the weighted error is: [[0.14285714]]\n",
      "split: dim 0, thresh 0.90, thresh inequal: gt, the weighted error is: [[0.85714286]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.35714286]]\n",
      "split: dim 0, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.64285714]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: lt, the weighted error is: [[0.35714286]]\n",
      "split: dim 0, thresh 1.10, thresh inequal: gt, the weighted error is: [[0.64285714]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: lt, the weighted error is: [[0.35714286]]\n",
      "split: dim 0, thresh 1.20, thresh inequal: gt, the weighted error is: [[0.64285714]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.30, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.40, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.50, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.60, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.70, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.80, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: lt, the weighted error is: [[0.28571429]]\n",
      "split: dim 0, thresh 1.90, thresh inequal: gt, the weighted error is: [[0.71428571]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: lt, the weighted error is: [[0.85714286]]\n",
      "split: dim 0, thresh 2.00, thresh inequal: gt, the weighted error is: [[0.14285714]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: lt, the weighted error is: [[0.14285714]]\n",
      "split: dim 1, thresh 0.89, thresh inequal: gt, the weighted error is: [[0.85714286]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: lt, the weighted error is: [[0.5]]\n",
      "split: dim 1, thresh 1.00, thresh inequal: gt, the weighted error is: [[0.5]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.11, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.22, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.33, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.44, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.55, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.66, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.77, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.88, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: lt, the weighted error is: [[0.57142857]]\n",
      "split: dim 1, thresh 1.99, thresh inequal: gt, the weighted error is: [[0.42857143]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: lt, the weighted error is: [[0.85714286]]\n",
      "split: dim 1, thresh 2.10, thresh inequal: gt, the weighted error is: [[0.14285714]]\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst: [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst: [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wshengj\\AppData\\Local\\Temp\\ipykernel_26280\\928259779.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16)))\n"
     ]
    }
   ],
   "source": [
    "classifierArray = adaBoostTrainDS(datMat, classLabels, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1577dbe0-2496-4d7e-93fe-9cad7cc8ed37",
   "metadata": {},
   "source": [
    "根据`adaBoostTrainDS()`函数的定义，其返回值为一个包含所有弱分类器的数组，我们可以通过调用`classifierArray`变量来查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b905a370-a697-4dfa-83cd-83e8b26e3a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dim': 0,\n",
       "  'thresh': np.float64(1.3),\n",
       "  'ineq': 'lt',\n",
       "  'alpha': 0.6931471805599453},\n",
       " {'dim': 1,\n",
       "  'thresh': np.float64(1.0),\n",
       "  'ineq': 'lt',\n",
       "  'alpha': 0.9729550745276565},\n",
       " {'dim': 0,\n",
       "  'thresh': np.float64(0.9),\n",
       "  'ineq': 'lt',\n",
       "  'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0298ba-cdfa-449c-b74a-cba3347ae7e5",
   "metadata": {},
   "source": [
    "该数组包含三个字典，其中包含了分类所需要的所有信息。此时，一个分类器已经构建成功，接下来我们需要测试错误率来观察它的效果。\n",
    "\n",
    "在下一节，我们将编写代码来实现测试功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87744cf-817a-41df-8ce1-4a053b48befb",
   "metadata": {},
   "source": [
    "## 7.5 测试算法：基于AdaBoost的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e001210d-24cb-4dd2-b4c5-231275746492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass, classifierArr):\n",
    "    dataMatrix = np.asmatrix(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.asmatrix(np.zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix,\n",
    "                                 classifierArr[i]['dim'],\n",
    "                                 classifierArr[i]['thresh'],\n",
    "                                 classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha'] * classEst\n",
    "        print(aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16f505d0-1245-40ec-ac56-8947754f988e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifierArr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adaClassify([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], \u001b[43mclassifierArr\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifierArr' is not defined"
     ]
    }
   ],
   "source": [
    "adaClassify([0, 0], classifierArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfcf82-9296-423c-bcf4-56075e4123fd",
   "metadata": {},
   "source": [
    "## 7.6 示例：在一个难数据集上应用AdaBoost\n",
    "\n",
    "本节我们将在第5章给出的马疝病数据集上应用AdaBoost分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17474409-0c24-4f7d-b2ca-a2de4c1bad56",
   "metadata": {},
   "source": [
    "|||示例：在一个难数据集上的AdaBoost应用|\n",
    "|---|---|:---|\n",
    "|(1)|收集数据：|提供的文本文件。|\n",
    "|(2)|准备数据：|确保类别标签是+1和-1而非1和0。|\n",
    "|(3)|分析数据：|手工检查数据。|\n",
    "|(4)|训练算法：|在数据上，利用`adaBoostTrainDS()`函数训练出一系列的分类器。|\n",
    "|(5)|测试算法：|我们拥有两个数据集。在不采用随机抽样的方法下，我们就会对AdaBoost和Logistic回归的结果进行完全对等的比较。|\n",
    "|(6)|使用算法：|观察该例子上的错误率。不过，也可以构建一个Web网站，让驯马师输入马的症状然后预测马是否会死去。|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f450946-8692-451c-aa33-aaa863cea594",
   "metadata": {},
   "source": [
    "## 7.7 非均衡分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6f15f-feca-4355-8b95-08ac8d89bf34",
   "metadata": {},
   "source": [
    "### 7.7.1 其他分类性能度量指标：正确率、召回率及ROC曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c77a4-9871-4138-bf21-20f224734dcf",
   "metadata": {},
   "source": [
    "### 7.7.2 基于代价函数的分类器决策控制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91981b89-cbc8-405b-b5a5-0d24c5e6dd01",
   "metadata": {},
   "source": [
    "### 7.7.3 处理非均衡问题的数据抽样方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916d599-2373-4bfb-a392-b95110e6a70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
